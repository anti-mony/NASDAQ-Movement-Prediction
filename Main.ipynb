{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Using News Data to Predict Movements in the Financial Movements_**\n",
    "\n",
    "We'll be using two apporaches here:\n",
    "\n",
    "* Continuous Bag of Words Model\n",
    "* RNN Models using Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/antimony/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/antimony/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as tud\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import operator\n",
    "import os, math\n",
    "import random\n",
    "import copy\n",
    "import string\n",
    "import multiprocessing as mp\n",
    "\n",
    "from split_data import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seeds so the experiments can be replicated exactly\n",
    "random.seed(72689)\n",
    "np.random.seed(72689)\n",
    "torch.manual_seed(72689)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(72689)\n",
    "\n",
    "# Global class labels.\n",
    "POS_LABEL = 'up'\n",
    "NEG_LABEL = 'down'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading in all the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>OpenMove</th>\n",
       "      <th>CloseMove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top U.S. General Praises Iran-Backed Shiite Mi...</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>The top commander of the U.S.-led coalition ag...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extremists Turn to a Leader to Protect Western...</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>As the founder of the Traditionalist Worker Pa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How Julian Assange evolved from pariah to paragon</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>President-elect Donald Trump tweeted some pra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>House panel recommends cutting funding for Pla...</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>A House panel formed by Republicans to invest...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Missouri Bill: Gun-Banning Businesses Liable f...</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>As Missouri lawmakers convene for the 2017 leg...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date  \\\n",
       "0  Top U.S. General Praises Iran-Backed Shiite Mi...  2017-01-04   \n",
       "1  Extremists Turn to a Leader to Protect Western...  2017-01-04   \n",
       "2  How Julian Assange evolved from pariah to paragon  2017-01-04   \n",
       "3  House panel recommends cutting funding for Pla...  2017-01-04   \n",
       "4  Missouri Bill: Gun-Banning Businesses Liable f...  2017-01-04   \n",
       "\n",
       "                                             Content  OpenMove  CloseMove  \n",
       "0  The top commander of the U.S.-led coalition ag...       1.0        1.0  \n",
       "1  As the founder of the Traditionalist Worker Pa...       1.0        1.0  \n",
       "2   President-elect Donald Trump tweeted some pra...       1.0        1.0  \n",
       "3   A House panel formed by Republicans to invest...       1.0        1.0  \n",
       "4  As Missouri lawmakers convene for the 2017 leg...       1.0        1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"ProcessedData/CombinedData.csv\")\n",
    "all_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using a Small Subset of Data fro Development*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>OpenMove</th>\n",
       "      <th>CloseMove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another government shutdown over Obamacare? On...</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>\\nThis is the web version of VoxCare, a daily ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tourists Helped Fatten Him Up; Now Thai Monkey...</td>\n",
       "      <td>2017-05-19</td>\n",
       "      <td>[Whether he likes it or not, a morbidly obese ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indian Premier, in Israel Visit, Seeks to Brea...</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>JERUSALEM — Prime Minister Benjamin Netanyahu ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiribati Ends Aerial Search for Missing Ferry ...</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>WELLINGTON, New Zealand — The aerial search fo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The American Model</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>Amidst       a string of pat introductory refl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date  \\\n",
       "0  Another government shutdown over Obamacare? On...  2017-04-24   \n",
       "1  Tourists Helped Fatten Him Up; Now Thai Monkey...  2017-05-19   \n",
       "2  Indian Premier, in Israel Visit, Seeks to Brea...  2017-07-05   \n",
       "3  Kiribati Ends Aerial Search for Missing Ferry ...  2018-03-21   \n",
       "4                                 The American Model  2017-07-28   \n",
       "\n",
       "                                             Content  OpenMove  CloseMove  \n",
       "0  \\nThis is the web version of VoxCare, a daily ...       1.0        1.0  \n",
       "1  [Whether he likes it or not, a morbidly obese ...       1.0        1.0  \n",
       "2  JERUSALEM — Prime Minister Benjamin Netanyahu ...       0.0        0.0  \n",
       "3  WELLINGTON, New Zealand — The aerial search fo...       0.0        0.0  \n",
       "4  Amidst       a string of pat introductory refl...       0.0        0.0  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = all_data.sample(1000, random_state=68)\n",
    "data_sample.reset_index(drop=True, inplace=True)\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data For Feeding Into The Model\n",
    "\n",
    "Preprocessing Involves (in our case):\n",
    "* Turning All Words into lower/upper case, Normalization\n",
    "* removing punctuations, accent marks and other diacritics\n",
    "* removing stop words, sparse terms, and particular words\n",
    "* Stemming using a Porter Stemmer from NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all Punctuation\n",
    "def remove_punctuation(text):\n",
    "    more_puncs = '—'+ '’'+ '“'+ '”'+ '…'\n",
    "    return text.translate(str.maketrans('', '', string.punctuation+more_puncs))\n",
    "\n",
    "# Removing all Stop Words\n",
    "def remove_stopwords(text, stop_words):\n",
    "    text = word_tokenize(text)\n",
    "    return  \" \".join([i for i in text if i not in stop_words])\n",
    "\n",
    "def stem(text, stemmer):\n",
    "    text = word_tokenize(text)\n",
    "    return \" \".join([stemmer.stem(i) for i in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre_process function below performs all the preprocessing we defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    # Normalization\n",
    "    df['Title'] = df['Title'].str.lower()\n",
    "    df['Content'] = df['Content'].str.lower()\n",
    "\n",
    "    # Removing Punctuation\n",
    "    df['Title'] = df['Title'].apply(remove_punctuation)\n",
    "    df['Content'] = df['Content'].apply(remove_punctuation)\n",
    "    \n",
    "    STOP_WORDS = set(stopwords.words('english'))\n",
    "    # Remove Stopwords\n",
    "    df['Title'] = df['Title'].apply(remove_stopwords, args=(STOP_WORDS, ))\n",
    "    df['Content'] = df['Content'].apply(remove_stopwords, args=(STOP_WORDS, ))\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    df['Title'] = df['Title'].apply(stem, args=(stemmer,))\n",
    "    df['Content'] = df['Content'].apply(stem, args=(stemmer,))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We run the pre_process function in parallel to make it faster using the Multi-Processing Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>OpenMove</th>\n",
       "      <th>CloseMove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anoth govern shutdown obamacar trump want</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>web version voxcar daili newslett vox latest t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tourist help fatten thai monkey diet</td>\n",
       "      <td>2017-05-19</td>\n",
       "      <td>whether like morbidli obes wild monkey thailan...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indian premier israel visit seek break barrier...</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>jerusalem prime minist benjamin netanyahu long...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiribati end aerial search miss ferri passeng ...</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>wellington new zealand aerial search ferri kir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american model</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>amidst string pat introductori reflect recent ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date  \\\n",
       "0          anoth govern shutdown obamacar trump want  2017-04-24   \n",
       "1               tourist help fatten thai monkey diet  2017-05-19   \n",
       "2  indian premier israel visit seek break barrier...  2017-07-05   \n",
       "3  kiribati end aerial search miss ferri passeng ...  2018-03-21   \n",
       "4                                     american model  2017-07-28   \n",
       "\n",
       "                                             Content  OpenMove  CloseMove  \n",
       "0  web version voxcar daili newslett vox latest t...       1.0        1.0  \n",
       "1  whether like morbidli obes wild monkey thailan...       1.0        1.0  \n",
       "2  jerusalem prime minist benjamin netanyahu long...       0.0        0.0  \n",
       "3  wellington new zealand aerial search ferri kir...       0.0        0.0  \n",
       "4  amidst string pat introductori reflect recent ...       0.0        0.0  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing in Parallel\n",
    "n_threads = mp.cpu_count()-1\n",
    "data_pieces = np.array_split(data_sample, n_threads)\n",
    "\n",
    "pool = mp.Pool(n_threads)\n",
    "data_sample = pd.concat(pool.map(pre_process, data_pieces))\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for the CBOW Model\n",
    "\n",
    "* Building the Vocabulary (Using Spacy) | **MAX_VOCAB_SIZE** = 25000\n",
    "* Splitting the data for Test and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Data and Storing it such that torch text can easily ingest it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(df=data_sample[['Content', 'CloseMove']],prefix='dev',seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val, test = data.TabularDataset.splits(\n",
    "        path='./ProcessedData/', train='dev_train.csv',\n",
    "        validation='dev_val.csv', test='dev_test.csv', format='csv',\n",
    "        fields=[('Text', TEXT), ('Label', LABEL)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sanity Check for Vocabulary and Labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<unk>',\n",
       "  '<pad>',\n",
       "  'said',\n",
       "  'trump',\n",
       "  'mr',\n",
       "  'nt',\n",
       "  'would',\n",
       "  'one',\n",
       "  'year',\n",
       "  'peopl'],\n",
       " ['1.0', '0.0'])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TEXT.vocab.itos[:10]), (LABEL.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
